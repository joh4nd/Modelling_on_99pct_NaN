{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# revision of answer inspection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import glob \n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "# import numpy as np\n",
    "import bin.rebel_decode as rd\n",
    "\n",
    "\n",
    "\n",
    "######################################\n",
    "######### inspect one sample #########\n",
    "######################################\n",
    "\n",
    "p_info = rd.parse_public_data(\"../data/0001_public.txt\")\n",
    "COT=p_info.get_cot() # df of messenger's cotraveller at t\n",
    "NEA=p_info.get_nea() # df of messenger's closest star\n",
    "LOC=p_info.get_loc() # df of messenger's location\n",
    "FLAVOUR_DICT=p_info.get_flavour_dict() # dict of messenger's flavour/msg_type\n",
    "REBS=p_info.get_rebs() # semi-dict of messenger's co-travellers\n",
    "rebs_df=p_info.get_rebs_df() # added method to exract df\n",
    "\n",
    "\"\"\" plan\n",
    "1. use co-traveller info to determine shipmembers and ship identities\n",
    "2. use ship info to impute on all known shipmembers:\n",
    "    (a) nearest star and perhaps\n",
    "    (b) approximate location    \n",
    "\n",
    "\n",
    "3. concatenate the 10 sample dfs\n",
    "4. to do:\n",
    "    (a) i. join with truth data\n",
    "        ii. carry out multiple imputation\n",
    "    (b) eventually remove missing values\n",
    "\n",
    "?. inspect data\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"Inspect each sample\n",
    "\n",
    "1) What is the number of unique rebel names?\n",
    " - is it ~30?\n",
    "\n",
    "2) What is the number of unique\n",
    "2.1) leaked COT\n",
    "2.2) leaked LOC: xyz\n",
    "2.3) leaked NEA\n",
    "2.4) t\n",
    "\n",
    "\n",
    "3) What is the mean\n",
    "3.1) leaked LOC: xyz\n",
    "3.2) leaked NEA\n",
    "3.3) t\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" 1. determine shipmembers and ship identities\n",
    "We know that some rebels travel together at all times. We can tie the rebels together using the names and the leaked cotraveller names (including who leaked the names).\n",
    "\n",
    "a. Make a graph called relations based on the rebels relationships to each other through leaked information about who they travel with.\n",
    "b. Extract the ships based on observed relations using `connected_components`.\n",
    "c. Use `enumerate` to assign unique shipnumbers to each ship. Finally, use the shipnumber to determine the ship of each messenger/rebel.\n",
    "d. To this end, use dictionary comprehension i.e. a method to make a dictionary, that is, {key: value} pairs.\n",
    "e. Dict comprhension syntax is {new_key:new_value for item in iterable}.\n",
    "f. We use two for loops:\n",
    "    i. the first to loop through each `shipnumber, ship`-tuple returned by enumerate e.g. 4 connected components;\n",
    "    ii. the second to loop through each rebel in the given instance of a ship (ship is a string of rebel names, so e.g. Finn, Marie, Ane) defining the {rebel: shipnumber} key-value pairs.\n",
    "\"\"\"\n",
    "relations = nx.from_pandas_edgelist(COT, source='messenger', target='cotraveller') # graph of nodes and edges\n",
    "print(list(nx.connected_components(relations))) # dict-lists of connected rebels\n",
    "print(list(enumerate((nx.connected_components(relations))))) # given numbers in tuples as (number, {'rebel, names, here'})\n",
    "ships = {rebel: shipnumber for shipnumber, ship in enumerate(nx.connected_components(relations), start=1) for rebel in ship} # if len(ship)>1 else np.nan\n",
    "\n",
    "# Add ships to rebs_df\n",
    "rebs_df['ship'] = rebs_df['messenger'].map(ships)\n",
    "print('How many rebels are not aboard a ship?\\n', rebs_df['ship'].isna().sum())\n",
    "print('How many groups of rebels aka ships are there?\\n',rebs_df.ship.nunique())\n",
    "print('What are the groups?',rebs_df.ship.value_counts())\n",
    "print(pd.Series(ships))\n",
    "\n",
    "\n",
    "\"\"\" 2. impute known shipmembers'\n",
    "    (a) NEA nearest star and perhaps\n",
    "    (b) LOC approximate location \n",
    "\n",
    "    1) messenger to messenger\n",
    "    2) messenger to ship\n",
    "\"\"\"\n",
    "rebs_df = pd.merge(rebs_df,NEA[['messenger','t','closestStar']], how='left',on=['messenger','t'])\n",
    "NEA['ship'] = NEA['messenger'].map(ships)\n",
    "rebs_df = pd.merge(rebs_df,NEA[['t','ship','closestStar']]\n",
    "                   ,how='left',on=['ship','t'])\\\n",
    "                   .drop_duplicates(subset=['t','messenger','ship','closestStar',])\n",
    "rebs_df = pd.merge(rebs_df,LOC[['messenger','t','x','y','z']], how='left',on=['messenger','t']) # consider averaging leaked loc etc.\n",
    "LOC['ship'] = LOC['messenger'].map(ships)\n",
    "rebs_df = pd.merge(rebs_df,LOC[['t','ship','x','y','z']]\n",
    "                   ,how='left',on=['ship','t'])\\\n",
    "                   .drop_duplicates(subset=['t','messenger','ship','x'])\n",
    "\n",
    "# counting leak types and number of leakers per type\n",
    "print(rebs_df.info())\n",
    "print(rebs_df.value_counts('msg_type'))\n",
    "print(rebs_df.groupby(['msg_type'])['messenger'].nunique())\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
