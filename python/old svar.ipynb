{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REBS\n",
    "# generate df because REBS appears to be dict to be a bit special or non-dict\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "rebs_df2 = pd.read_csv('C:/Users/Johan/opg_RR/out/0001_public.txt',\n",
    "                 header=None, engine='python',\n",
    "                 sep='t=(\\d+), (\\w+), (\\w+), (.*)').dropna(how='all', axis=1) # regex from rebel_decode.py\n",
    "rebs_df2.columns=['t', 'msg_type', 'reb', 'msg_content']\n",
    "rebs_df2 = rebs_df2.sort_values('reb')\n",
    "rebs_df2.reset_index(drop=True)\n",
    "\n",
    "rebs_df2.value_counts('msg_type') # what type of leaks are most common?\n",
    "# can be run by two factors:\n",
    "# travellers leaking cotraveller also leak more often, or\n",
    "# there are more travellers that leak cotraveller than travellers leaking other msg_types\n",
    "\n",
    "# restructure msg long to wide \n",
    "rebs_df3=rebs_df2.loc[rebs_df2['msg_type'].isin(['COT','NEA'])].pivot(index=['t', 'reb'],\n",
    "                        columns='msg_type').reset_index() # (location coordinates in parenthesis fails to be pivotted)\n",
    "rebs_df2.loc[rebs_df2['msg_type'] == 'LOC','msg_content'] = rebs_df2.loc[rebs_df2['msg_type'] == 'LOC','msg_content'].str.replace(r'\\(','',regex=True).copy().str.replace(r'\\)','',regex=True).copy()\n",
    "rebs_df2[['x','y','z']] = rebs_df2.loc[rebs_df2['msg_type'] == 'LOC','msg_content'].str.split(pat=',',regex=True,expand=True).copy()\n",
    "rebs_df4 = rebs_df2[rebs_df2['msg_type'] == 'LOC']\n",
    "rebs_df4 = rebs_df4[['t','reb','x','y','z']]\n",
    "rebs_df3.columns = ['_'.join(col_X).rstrip('_') for col_X in rebs_df3.columns.values]\n",
    "rebs_df5 = pd.concat([rebs_df3,rebs_df4],keys=['t','reb'], ignore_index=True).sort_values(['t','reb']).reset_index(level=None,drop=True) #, drop=True)#.droplevel([0,1]) #['t']\n",
    "rebs_df5\n",
    "\n",
    "\n",
    "\n",
    "# data types\n",
    "rebs_df5.convert_dtypes()\n",
    "rebs_df5[['x','y','z']] = rebs_df5[['x','y','z']].astype(float)\n",
    "\n",
    "# expand df size to mission statement of 1000*reb rows\n",
    "rebs_df6 = rebs_df5.set_index('t')\\\n",
    "            .groupby('reb')\\\n",
    "            .apply(lambda df_x: df_x.reindex(range(1, 1000+1)))\\\n",
    "            .drop('reb', axis=1).reset_index()\n",
    "\n",
    "# inspect\n",
    "rebs_df6.describe(include='all')\n",
    "\n",
    "\n",
    "\n",
    "# From mission statement we know with certainty where some rebels are. \n",
    "# We also know with certainty that some rebels travel together at all times.\n",
    "# We can tie the rebels together using the names and the leaked cotraveller\n",
    "# names (including who leaked the names). This may enable us to impute values. \n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "rebs_df6_sub_no_na = rebs_df6.dropna(subset=['msg_content_COT']) # we dont want NaNs in the network\n",
    "relations = nx.from_pandas_edgelist(rebs_df6_sub_no_na, source='reb', target='msg_content_COT')\n",
    "\n",
    "# figure out the number of ships based on ties in the relations with \n",
    "# connected_components, and assign shipnumber to names with enumerate.\n",
    "ships = {r: t for t, s in enumerate((s for s in nx.connected_components(relations)\\\n",
    "                                      if len(s)>1), start=1) for r in s}\n",
    "\n",
    "pd.Series(ships) # list all passengers of each ship in the graded assignment\n",
    "\n",
    "# Add ships to df\n",
    "rebs_df6['ship'] = rebs_df6['reb'].map(ships)\n",
    "rebs_df6.describe(include='all')\n",
    "rebs_df6.value_counts('ship')\n",
    "rebs_df6['ship'].isna().sum() # all rebels are aboard a ship\n",
    "\n",
    "# Because we now the ships that the rebels aboard, there is not\n",
    "# additional information in  msg_content_COT: we drop it.\n",
    "rebs_df7 = rebs_df6.drop('msg_content_COT', axis=1)\n",
    "\n",
    "# Knowing the ships of all rebels, we can impute known x,y,z coordinates\n",
    "# of some rebels at a given time t to cotravellers on the same ship.\n",
    "# i.e. join on time and ship number to get LOC with certainty.\n",
    "rebs_df4['ship'] = rebs_df4['reb'].map(ships) # add ships to list of rebs with LOC leaks\n",
    "rebs_df8 = rebs_df7[['reb','t','ship','msg_content_NEA']].merge(rebs_df4, on=['t','ship'], how='left', suffixes=('_left','_right'))\n",
    "rebs_df8[['x','y','z']] = rebs_df8[['x','y','z']].astype(float)\n",
    "test = rebs_df8[rebs_df8.duplicated(subset=['t','reb_left','ship'], keep='first')] # 143 dups because merge not on rebels\n",
    "test2 = rebs_df8[rebs_df8.duplicated(subset=['t','reb_left','ship'], keep='last')]\n",
    "# rebs_df8.describe(include='all') # 143 dups\n",
    "test\n",
    "test2\n",
    "# rebs_df8[rebs_df8.duplicated(subset=['t','reb_right','ship'], keep='first')]\n",
    "\n",
    "\n",
    "rebs_df7[rebs_df7.duplicated()]\n",
    "\n",
    "# # fundamentally wrong wrong approach--to drop dups on merge right df--because \n",
    "# rebs_df8 = rebs_df7.merge(rebs_df4_2.drop_duplicates(subset=['t','ship']), on=['t','ship'], how='left', suffixes=('_left','_right')) \n",
    "# # drop dups afterwards: warning: are we dropping the correct rows?\n",
    "# rebs_df8 = rebs_df7.merge(rebs_df4_2, on=['t','ship'], how='left', suffixes=('_left','_right')).drop_duplicates(subset=['t','reb','ship'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit\n",
    "\n",
    "# Knowing the ships of all rebels, we can impute known x,y,z coordinates\n",
    "# of some rebels on some ships at a given time to cotravellers on the same ship.\n",
    "# I.e. join on time and ship to get certain LOCs.\n",
    "rebs_df = rebs_df.merge(LOC, on=['t','ship'], how='left')\n",
    "rebs_df.describe(include='all')\n",
    "rebs_df['duplicate'] = rebs_df.duplicated(subset=['t','messenger_x','ship'])\n",
    "\n",
    "# it turns out that, at least in 0001_public and 0001_truth, some rebels do not\n",
    "# leak totally similar information about their positions at a given time.\n",
    "# E.g. Yolanda and Steve are in the same ship, and yet at T443 they are located\n",
    "# somewhat differently according to public information, but not according to truth.\n",
    "# The leaked signals are either false (biased) or erronous.\n",
    "\n",
    "# We already know some coordinates with certainty\n",
    "LOC.describe(include='all')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# approach to calculating the analytical function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset into a pandas DataFrame\n",
    "data = pd.read_csv('mydata.csv')\n",
    "\n",
    "# Filter the relevant columns and clean any missing or invalid data\n",
    "cols_to_keep = ['t', 'dimension1', 'dimension2', 'rate']\n",
    "data = data[cols_to_keep].dropna()\n",
    "\n",
    "# Group the data by time and the other dimensions that vary with time\n",
    "grouped_data = data.groupby(['t', 'dimension1', 'dimension2'])\n",
    "\n",
    "# Compute the number of non-NaN values for each group\n",
    "non_nan_counts = grouped_data['column_of_interest'].count()\n",
    "\n",
    "# Compute the total number of values (including NaN) for each group\n",
    "total_counts = grouped_data.size()\n",
    "\n",
    "# Calculate the rate of non-NaN values as the ratio of step 4 to step 5\n",
    "rates = non_nan_counts / total_counts\n",
    "\n",
    "# Compute the rates of observations for each group\n",
    "# rates = grouped_data['rate'].mean()\n",
    "\n",
    "# Visualize the rates of observations over time\n",
    "plt.plot(rates)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Rate')\n",
    "plt.show()\n",
    "\n",
    "# Fit a suitable analytical function to the rates of observations using regression analysis\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def analytical_function(t, a, b, c):\n",
    "    return a *\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"_summary_\n",
    "\n",
    "It turns out that, at least in 0001_public and 0001_truth, some rebels do not\n",
    "leak identical information about their positions at a given time; resolution varies.\n",
    "E.g. Yolanda and Steve are in the same ship, and yet at T443 they are located\n",
    "somewhat differently according to public information, but not according to truth.\n",
    "The leaked signals are either false (biased) or erronous.\n",
    "\n",
    "# impute averages of leaked coordinates per ship at a given time on the rest\n",
    "# LOC['ship'] = LOC['messenger'].map(ships)\n",
    "# LOC.describe(include='all') # do we have some coordinates of all ships?\n",
    "ship_LOC_avg = LOC.groupby(['t','ship'], as_index=False).mean(numeric_only=True)[['t','ship','x','y','z']]\n",
    "ship_LOC_avg.columns=['t', 'ship', 'x_avg', 'y_avg','z_avg']\n",
    "rebs_df = rebs_df.merge(ship_LOC_avg, how='left',on=['ship','t'])\n",
    "rebs_df['x','y','z'] = rebs_df['x','y','z'].fillna(rebs_df['x_avg','y_avg','z_avg'])\n",
    "rebs_df\n",
    "rebs_df.describe(include='all')\n",
    "# perhaps forward fill NaN with some regression between values\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we treat leaked positions (and perhaps NEA) as samples of the truth?\n",
    "# df_rebs['x','x_truth'].hist(by=df['msg_type']) # or perhaps t\n",
    "\n",
    "# If we may, then perhaps we can \n",
    "# Do the distribution of the sample vary from the truth? => then not missing completely at random\n",
    "\n",
    "\n",
    "\n",
    "    # if true ship movements are really not completely random\n",
    "    # then it informs how we can handle (impute) missing values\n",
    "    # of columns predicting about movements.\n",
    "    # mis complete rand: mean, median, mode, etc\n",
    "    # mis at rand: multiple imput, regress imput\n",
    "    # miss not at rand: pattern substitution, maxumum likelihood estimation\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# df_rebs['x','x_truth'].hist(by=df['msg_type']) # or perhaps t\n",
    "\n",
    "\n",
    "# add leaked coordinates\n",
    "# rebs_df = pd.merge(rebs_df,LOC[['messenger','t','x','y','z']], how='left',on=['messenger','t'])\n",
    "    # must related to coordinates of all shipmembers, but we dont know how\n",
    "    # bias and error: what function maps signals from truth?\n",
    "    # If the missingness of the data can be explained by confounders/variables we observe\n",
    "    # then may assume the leaked coordinates are missing at random.\n",
    "    # If the distribution of xyz is likely to be similar for \n",
    "    # 1) rebel and t and 2) msg_type(!)\n",
    "\n",
    "\n",
    "# # https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.interpolate.html\n",
    "# plot timeseries ts['t','x'] \n",
    "# ts.plot()\n",
    "# ts.interpolate().plot() # https://pandas.pydata.org/docs/user_guide/missing_data.html\n",
    "\n",
    "# # test different methods\n",
    "# methods = [\"linear\", \"quadratic\", \"cubic\"] # interpolatiom AKIMA for smooth? \n",
    "# df = pd.DataFrame({m: ser.interpolate(method=m) for m in methods})\n",
    "# df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare distributions to infer missing at random or completely at random .\n",
    "# We might compare distributions of positions at NEA leaks--which have no error--\n",
    "# and where position is equal to true position, with distributions of all positions;\n",
    "# because that might show that \n",
    "\n",
    "# messages = truth.get_messages()\n",
    "# messages['ship'] = messages['shipid'].apply(lambda shipid_x: int(shipid_x.split('_')[1])) # split, tak the last item, to int\n",
    "# messages.rename({'x': 'x_truth', 'y': 'y_truth', 'z': 'z_truth'}, axis=1, inplace=True)\n",
    "# messages = messages[['t','x_truth','y_truth','z_truth','ship','msg']]\n",
    "# # sample_true = messages.loc[messages['msg'] == 'NEA']\n",
    "# rebs_df_wtruth.describe()\n",
    "# # messages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare distribution of leaked positions by ship with true positions by ship, at t\n",
    "# so understand a bit better the error/bias, perhaps so as to impute on an educated guess\n",
    "# (and by implication, without multiple imputation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We may also get a sense of the distributions, and therefore \n",
    "# their probabilities, of the respective dimensions, \n",
    "# unconditionally of factors necesarry to define rebel movement.\n",
    "ship_movements.z_truth.hist()\n",
    "ship_movements.x_truth.hist()\n",
    "ship_movements.y_truth.hist()\n",
    "ship_movements[['x_truth', 'y_truth', 'z_truth']].hist()\n",
    "print('z_skew', ship_movements.z_truth.skew())\n",
    "print('x_skew', ship_movements.x_truth.skew())\n",
    "print('y_skew', ship_movements.y_truth.skew())\n",
    "print('z_kurt', ship_movements.z_truth.kurt())\n",
    "print('x_kurt', ship_movements.x_truth.kurt())\n",
    "print('y_kurt', ship_movements.y_truth.kurt())\n",
    "\n",
    "from scipy.stats import shapiro\n",
    "test_stat, p_value = shapiro(ship_movements[['x_truth','y_truth','z_truth']]) # joint distribution not normal\n",
    "print('Shapiro-Wilk test statistic:', test_stat,', ', 'p-value:',p_value)\n",
    "from scipy.stats import entropy\n",
    "print(entropy(ship_movements['x_truth']))\n",
    "print(entropy(ship_movements['y_truth']))\n",
    "print(entropy(ship_movements['z_truth']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2eff2d74f618fde222479b54118cc76f0f7af2cabe924adab209368f7b17212b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
